{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments, AutoModelWithLMHead, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load poetries text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Totale poesie processate: 766\n",
      "Lista autori:\n",
      "CAIO VALERIO CATULLO\n",
      "GIUSEPPE UNGARETTI\n",
      "JACK KEROUAC\n",
      "CARLO BETOCCHI\n",
      "ALESSANDRO MANZONI\n",
      "SALVATORE QUASIMODO\n",
      "JAMES JOYCE\n",
      "FRANCESCO D ASSISI\n",
      "PABLO NERUDA\n",
      "SAFFO\n",
      "WILLIAM BUTLER YEATS\n",
      "ARRIGO BOITO\n",
      "EDGAR ALLAN POE\n",
      "GIACOMO LEOPARDI\n",
      "JORGE LUIS BORGES\n",
      "NICCOLO UGO FOSCOLO\n",
      "OSCAR WILDE\n",
      "RUDYARD KIPLING\n",
      "VICTOR HUGO\n",
      "UMBERTO SABA\n",
      "ANNA ACHMATOVA\n",
      "VOLTAIRE\n",
      "ITALO CALVINO\n",
      "WILLIAM WORDSWORTH\n",
      "DANTE ALIGHIERI\n",
      "MICHELANGELO BUONARROTI\n",
      "ANNA FRANK\n",
      "EDUARDO DE FILIPPO\n",
      "ARTHUR RIMBAUD\n",
      "GIORGIO CAPRONI\n",
      "DINO BUZZATI\n",
      "MARCEL PROUST\n",
      "FRIEDRICH SCHILLER\n",
      "CHARLES BAUDELAIRE\n",
      "ALDA MERINI\n",
      "EMILY DICKINSON\n",
      "EDMONDO DE AMICIS\n",
      "CESARE PAVESE\n",
      "SAN PAOLO\n",
      "PRIMO LEVI\n",
      "GIOSUE CARDUCCI\n",
      "JOHN KEATS\n",
      "PIER PAOLO PASOLINI\n",
      "LUIGI PIRANDELLO\n",
      "WILLIAM BLAKE\n",
      "GUILLAUME APOLLINAIRE\n",
      "ADA NEGRI\n",
      "PAULO COELHO\n",
      "ROBERT FROST\n",
      "GIUSEPPE PARINI\n",
      "JOHN DONNE\n",
      "WILLIAM SHAKESPEARE\n",
      "GABRIELE D ANNUNZIO\n",
      "ALDO PALAZZESCHI\n",
      "EZRA POUND\n",
      "GUIDO CAVALCANTI\n",
      "THOMAS STEARNS ELIOT\n",
      "FRANCESCO PETRARCA\n",
      "CORRADO GOVONI\n",
      "CHARLES BUKOWSKI\n",
      "LEWIS CARROLL\n",
      "EUGENIO MONTALE\n",
      "GIOVANNI PASCOLI\n",
      "-------------------------\n",
      "Train dataset length: 651\n",
      "Test dataset length: 115\n"
     ]
    }
   ],
   "source": [
    "#%% open poetries file and keep only authors with more than 5 poetries\n",
    "filename = os.path.join('data_collection', 'poestries_dict.pkl')\n",
    "with open(filename, 'rb') as f:\n",
    "    poetries_dict = pickle.load(f)\n",
    "\n",
    "# define authors to keep\n",
    "authors_to_keep = [\n",
    "    \"JOHN KEATS\",\n",
    "    \"JOHN DONNE\",\n",
    "    \"LUIGI PIRANDELLO\",\n",
    "    \"ALDO PALAZZESCHI\",\n",
    "    \"ANNA ACHMATOVA\",\n",
    "    \"GIACOMO LEOPARDI\",\n",
    "    \"GIUSEPPE PARINI\",\n",
    "    \"SAFFO\",\n",
    "    \"EDMONDO DE AMICIS\",\n",
    "    \"FRANCESCO PETRARCA\",\n",
    "    \"WILLIAM WORDSWORTH\",\n",
    "    \"ROBERT FROST\",\n",
    "    \"DINO BUZZATI\",\n",
    "    \"MARCEL PROUST\",\n",
    "    \"VOLTAIRE\",\n",
    "    \"GUILLAUME APOLLINAIRE\",\n",
    "    \"EZRA POUND\",\n",
    "    \"JAMES JOYCE\",\n",
    "    \"GIUSEPPE UNGARETTI\",\n",
    "    \"SALVATORE QUASIMODO\",\n",
    "    \"WILLIAM BLAKE\",\n",
    "    \"JORGE LUIS BORGES\",\n",
    "    \"PRIMO LEVI\",\n",
    "    \"GABRIELE D ANNUNZIO\",\n",
    "    \"PAULO COELHO\",\n",
    "    \"EMILY DICKINSON\",\n",
    "    \"CHARLES BUKOWSKI\",\n",
    "    \"UMBERTO SABA\",\n",
    "    \"SAN PAOLO\",\n",
    "    \"FRIEDRICH SCHILLER\",\n",
    "    \"ARRIGO BOITO\",\n",
    "    \"WILLIAM SHAKESPEARE\",\n",
    "    \"CORRADO GOVONI\",\n",
    "    \"WILLIAM BUTLER YEATS\",\n",
    "    \"EDGAR ALLAN POE\",\n",
    "    \"VICTOR HUGO\",\n",
    "    \"ITALO CALVINO\",\n",
    "    \"ADA NEGRI\",\n",
    "    \"CARLO BETOCCHI\",\n",
    "    \"CESARE PAVESE\",\n",
    "    \"GIOVANNI PASCOLI\",\n",
    "    \"CHARLES BAUDELAIRE\",\n",
    "    \"JACK KEROUAC\",\n",
    "    \"GUIDO CAVALCANTI\",\n",
    "    \"CAIO VALERIO CATULLO\",\n",
    "    \"FRANCESCO D ASSISI\",\n",
    "    \"EDUARDO DE FILIPPO\",\n",
    "    \"THOMAS STEARNS ELIOT\",\n",
    "    \"NICCOLO UGO FOSCOLO\",\n",
    "    \"OSCAR WILDE\",\n",
    "    \"EUGENIO MONTALE\",\n",
    "    \"DANTE ALIGHIERI\",\n",
    "    \"PABLO NERUDA\",\n",
    "    \"ARTHUR RIMBAUD\",\n",
    "    \"ALESSANDRO MANZONI\",\n",
    "    \"RUDYARD KIPLING\",\n",
    "    \"ANNA FRANK\",\n",
    "    \"ALDA MERINI\",\n",
    "    \"PIER PAOLO PASOLINI\",\n",
    "    \"LEWIS CARROLL\",\n",
    "    \"GIOSUE CARDUCCI\",\n",
    "    \"GIORGIO CAPRONI\",\n",
    "    \"MICHELANGELO BUONARROTI\"\n",
    "]\n",
    "\n",
    "poetries = []\n",
    "author_list = []\n",
    "for key in poetries_dict:\n",
    "    author = key.replace('-', ' ').upper()\n",
    "    if author in authors_to_keep:\n",
    "        for p in poetries_dict[key]:\n",
    "            poetries.append(p)\n",
    "            author_list.append(author)\n",
    "\n",
    "print('-------------------------')\n",
    "print('Totale poesie processate: {}'.format(len(poetries)))\n",
    "print('Lista autori:')\n",
    "for author in set(author_list):\n",
    "    print(author)\n",
    "print('-------------------------')\n",
    "\n",
    "#%% prepare dataset\n",
    "\n",
    "table = str.maketrans('', '', '!\"#$%&\\'()*+-/:;<=>?@[\\\\]^_`{|}~¬ª‚Äî‚Ä¶¬π‚Äù¬®¬´‚Äò‚Äú¬¨ÀÜ')\n",
    "for i in range(len(poetries)):\n",
    "    poetries[i] = poetries[i].lower()\n",
    "    poetries[i] = poetries[i].replace(\"\\r\", \"\")\n",
    "    poetries[i] = poetries[i].replace(\"\\n\", \" \\n \")\n",
    "    poetries[i] = poetries[i].replace(\"  \", \" \")\n",
    "    poetries[i] = poetries[i].replace(\"√¢‚Ç¨‚Ñ¢\", \"'\")\n",
    "    poetries[i] = poetries[i].replace(\"‚Äô\", \" \")\n",
    "    # poetries[i] = poetries[i].replace(\",\", \" , \")\n",
    "    poetries[i] = poetries[i].replace(\".\", \". \")\n",
    "    poetries[i] = poetries[i].replace(\"  \", \" \")\n",
    "    poetries[i] = poetries[i].replace(\"√∫\", \"√π\")\n",
    "    poetries[i] = poetries[i].replace(\"√£\", \"a\")\n",
    "    poetries[i] = poetries[i].replace(\"√¢\", \"a\")\n",
    "    poetries[i] = poetries[i].replace(\"√≠\", \"√¨\")\n",
    "    poetries[i] = poetries[i].replace(\"√¥\", \"o\")\n",
    "    poetries[i] = poetries[i].replace(\"a¬©\", \"√®\")\n",
    "    poetries[i] = poetries[i].replace(\"√Ø\", \"i\")\n",
    "    poetries[i] = poetries[i].translate(table)\n",
    "poetries = np.array(poetries)\n",
    "authors = np.array(author_list)\n",
    "\n",
    "\n",
    "def build_text_files(poetries, dest_path):\n",
    "    data = ''\n",
    "    for text in poetries:\n",
    "        data = data + \"<|endoftext|>\" + text\n",
    "    with open(dest_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(data)\n",
    "\n",
    "train, test = train_test_split(poetries, test_size=0.15)\n",
    "\n",
    "build_text_files(train, os.path.join('data_collection', 'train_dataset.txt'))\n",
    "build_text_files(test, os.path.join('data_collection', 'test_dataset.txt'))\n",
    "\n",
    "print(\"Train dataset length: \" + str(len(train)))\n",
    "print(\"Test dataset length: \" + str(len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and tokenizer from pre-trained small italian GPT2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\apazzaglia00\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:588: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "c:\\Users\\apazzaglia00\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:54: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelWithLMHead.from_pretrained(\"GroNLP/gpt2-small-italian\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/gpt2-small-italian\")\n",
    "\n",
    "train_path = os.path.join('data_collection', 'train_dataset.txt')\n",
    "test_path = os.path.join('data_collection', 'test_dataset.txt')\n",
    "\n",
    "# train_encoded = tokenizer.encode('\\n'.join([text for text in train]))\n",
    "# train_decoded = tokenizer.decode(train_encoded)\n",
    "# with open(os.path.join('data_collection', 'train_dataset_encoded.txt'), 'w', encoding='utf-8') as f:\n",
    "#     f.write(train_decoded)\n",
    "\n",
    "def load_dataset(train_path,test_path,tokenizer):\n",
    "    train_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=train_path,\n",
    "          block_size=128)\n",
    "\n",
    "    test_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=test_path,\n",
    "          block_size=128)\n",
    "\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False,\n",
    "    )\n",
    "    return train_dataset, test_dataset, data_collator\n",
    "\n",
    "train_dataset, test_dataset, data_collator = load_dataset(train_path, test_path, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining fine-tuning parameters and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1750\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 165\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 165/165 [1:37:12<00:00, 26.42s/it]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 165/165 [1:37:12<00:00, 35.35s/it]\n",
      "Saving model checkpoint to models\\gpt2-poetries\n",
      "Configuration saved in models\\gpt2-poetries\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 5832.6908, 'train_samples_per_second': 0.9, 'train_steps_per_second': 0.028, 'train_loss': 4.583251953125, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in models\\gpt2-poetries\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=os.path.join(\"models\", \"gpt2-poetries\"), #The output directory\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    num_train_epochs=3, # number of training epochs\n",
    "    per_device_train_batch_size=32, # batch size for training\n",
    "    per_device_eval_batch_size=64,  # batch size for evaluation\n",
    "    eval_steps=200, # Number of update steps between two evaluations.\n",
    "    save_steps=200, # after # steps model is saved\n",
    "    warmup_steps=200, # number of warmup steps for learning rate scheduler\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model binaries is splitted in multiple files\n",
    "import bysp\n",
    "bysp.split_file(whole=os.path.join(\"models\", \"gpt2-poetries\", \"pytorch_model.bin\"), split_count=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model output with custom prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file models\\gpt2-poetries\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"GroNLP/gpt2-small-italian\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 100,\n",
      "      \"no_repeat_ngram_size\": 4,\n",
      "      \"num_beams\": 10,\n",
      "      \"repetition_penalty\": 10.0,\n",
      "      \"temperature\": 2.0,\n",
      "      \"top_k\": 20,\n",
      "      \"top_p\": 0.9\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30001\n",
      "}\n",
      "\n",
      "loading configuration file models\\gpt2-poetries\\config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"GroNLP/gpt2-small-italian\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 100,\n",
      "      \"no_repeat_ngram_size\": 4,\n",
      "      \"num_beams\": 10,\n",
      "      \"repetition_penalty\": 10.0,\n",
      "      \"temperature\": 2.0,\n",
      "      \"top_k\": 20,\n",
      "      \"top_p\": 0.9\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30001\n",
      "}\n",
      "\n",
      "loading weights file models\\gpt2-poetries\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at models\\gpt2-poetries.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "Using pad_token, but it is not set yet.\n",
      "c:\\Users\\apazzaglia00\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ..\\aten\\src\\ATen\\native\\BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "il tuo sorriso √® come un fiore \n",
      " nel cuore di tutti . la tua vita non ha senso \n",
      " in me nulla pi√π che tu sei il suo nome e ti sentirai felice \n",
      " ma quando si risveglierai al mio fianco le tue parole mi risuonano \n",
      " nella mia mente i tuoi sentimenti vanno dal dolore agli ideali \n",
      " dell'uomo a quelli del mondo. \n",
      " cos√¨ io ho amato tutto ci√≤ che avrei dovuto fare fino ai giorni nostri \n",
      " senza chiedermi mai\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-generation\", model=os.path.join(\"models\", \"gpt2-poetries\"), tokenizer=tokenizer)\n",
    "result = pipe(\"il tuo sorriso √® come\")[0]['generated_text']\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "923bb44e77603537bf5129924008506bd2cdd0af89ebee59c5e5508f0654874d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
